# Neural_Machine_Translation_using_RNN_Attention
Neural Machine Translation with Recurrent Neural Networks using attention mechanism. Evaluating this architecture by comparing its translation capability using two different recurrent cell types, namely Long Short-term Memory (LSTMs) and Gated Recurrent Units(GRUs), when given short sequence of words, versus when given a long sequence of words.
